{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reproduce of paper Graph Transformer Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### unzip dataset (the dataset is provided by the author)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  data/data.zip\n",
      "  inflating: ./data/ACM/.ipynb_checkpoints/ACM_data-checkpoint.ipynb  \n",
      "  inflating: ./data/ACM/.ipynb_checkpoints/Untitled-checkpoint.ipynb  \n",
      "  inflating: ./data/ACM/edges.pkl    \n",
      "  inflating: ./data/ACM/labels.pkl   \n",
      "  inflating: ./data/ACM/node_features.pkl  \n",
      "  inflating: ./data/DBLP/.ipynb_checkpoints/Untitled-checkpoint.ipynb  \n",
      "  inflating: ./data/DBLP/.ipynb_checkpoints/author_label-checkpoint.txt  \n",
      "  inflating: ./data/DBLP/.ipynb_checkpoints/paper_author-checkpoint.txt  \n",
      "  inflating: ./data/DBLP/.ipynb_checkpoints/small_data-checkpoint.ipynb  \n",
      "  inflating: ./data/DBLP/.ipynb_checkpoints/term-checkpoint.txt  \n",
      "  inflating: ./data/DBLP/.ipynb_checkpoints/total_data-checkpoint.ipynb  \n",
      "  inflating: ./data/DBLP/edges.pkl   \n",
      "  inflating: ./data/DBLP/labels.pkl  \n",
      "  inflating: ./data/DBLP/node_features.pkl  \n",
      "  inflating: ./data/IMDB/edges.pkl   \n",
      "  inflating: ./data/IMDB/labels.pkl  \n",
      "  inflating: ./data/IMDB/node_features.pkl  \n"
     ]
    }
   ],
   "source": [
    "!unzip -o -d ./data data/data.zip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from model import GTN\n",
    "import pickle\n",
    "from utils import f1_score,set_global_random_seed\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass   # substitute for argparse\n",
    "class Argument:\n",
    "    dataset: str  # choice in [\"ACM\",\"DBLP\",\"IMDB\"]\n",
    "    epoch: int = 40\n",
    "    node_dim: int = 64\n",
    "    num_channels: int = 2\n",
    "    lr: float = 0.005\n",
    "    weight_decay: float = 0.001\n",
    "    num_layers: int = 2\n",
    "    norm: str = 'true'\n",
    "    adaptive_lr: str = 'true'\n",
    "    seed:int =16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args:Argument):\n",
    "    device = torch.device(\"cuda:0\") \n",
    "    epochs = args.epoch\n",
    "    node_dim = args.node_dim\n",
    "    num_channels = args.num_channels\n",
    "    lr = args.lr\n",
    "    weight_decay = args.weight_decay\n",
    "    num_layers = args.num_layers\n",
    "    norm = args.norm\n",
    "    adaptive_lr = args.adaptive_lr\n",
    "    with open('./data/'+args.dataset+'/node_features.pkl','rb') as f:\n",
    "        node_features = pickle.load(f)\n",
    "    with open('./data/'+args.dataset+'/edges.pkl','rb') as f:\n",
    "        edges = pickle.load(f)\n",
    "    with open('./data/'+args.dataset+'/labels.pkl','rb') as f:\n",
    "        labels = pickle.load(f)\n",
    "    num_nodes = edges[0].shape[0]\n",
    "\n",
    "    for i,edge in enumerate(edges):\n",
    "        if i ==0:\n",
    "            A = torch.from_numpy(edge.todense()).type(torch.FloatTensor).unsqueeze(-1).to(device)\n",
    "        else:\n",
    "            A = torch.cat([A.to(device),torch.from_numpy(edge.todense()).type(torch.FloatTensor).unsqueeze(-1).to(device)], dim=-1)\n",
    "    A = torch.cat([A,torch.eye(num_nodes).type(torch.FloatTensor).unsqueeze(-1).to(device)], dim=-1)\n",
    "\n",
    "    node_features = torch.from_numpy(node_features).type(torch.FloatTensor).to(device)\n",
    "    print(\"node_features.shape\",node_features.shape)\n",
    "    train_node = torch.from_numpy(np.array(labels[0])[:,0]).type(torch.LongTensor).to(device)\n",
    "    train_target = torch.from_numpy(np.array(labels[0])[:,1]).type(torch.LongTensor).to(device)\n",
    "    valid_node = torch.from_numpy(np.array(labels[1])[:,0]).type(torch.LongTensor).to(device)\n",
    "    valid_target = torch.from_numpy(np.array(labels[1])[:,1]).type(torch.LongTensor).to(device)\n",
    "    test_node = torch.from_numpy(np.array(labels[2])[:,0]).type(torch.LongTensor).to(device)\n",
    "    test_target = torch.from_numpy(np.array(labels[2])[:,1]).type(torch.LongTensor).to(device)\n",
    "\n",
    "    num_classes = torch.max(train_target).item()+1\n",
    "    final_f1 = 0\n",
    "    for l in range(1):\n",
    "        model = GTN(num_edge=A.shape[-1],\n",
    "                            num_channels=num_channels,\n",
    "                            w_in = node_features.shape[1],\n",
    "                            w_out = node_dim,\n",
    "                            num_class=num_classes,\n",
    "                            num_layers=num_layers,\n",
    "                            norm=norm).to(device)\n",
    "        if adaptive_lr == 'false':\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=0.001)\n",
    "        else:\n",
    "            optimizer = torch.optim.Adam([{'params':model.weight},\n",
    "                                        {'params':model.linear1.parameters()},\n",
    "                                        {'params':model.linear2.parameters()},\n",
    "                                        {\"params\":model.layers.parameters(), \"lr\":0.5}\n",
    "                                        ], lr=0.005, weight_decay=0.001)\n",
    "        loss = nn.CrossEntropyLoss()\n",
    "        # Train & Valid & Test\n",
    "        best_val_loss = 10000\n",
    "        best_test_loss = 10000\n",
    "        best_train_loss = 10000\n",
    "        best_train_f1 = 0\n",
    "        best_val_f1 = 0\n",
    "        best_test_f1 = 0\n",
    "        print(\"ready to train\")\n",
    "        for i in range(epochs):\n",
    "            for param_group in optimizer.param_groups:\n",
    "                if param_group['lr'] > 0.005:\n",
    "                    param_group['lr'] = param_group['lr'] * 0.9\n",
    "            print('Epoch:  ',i+1)\n",
    "            model.zero_grad()\n",
    "            model.train()\n",
    "            loss,y_train,Ws = model(A, node_features, train_node, train_target)\n",
    "            train_f1 = torch.mean(f1_score(torch.argmax(y_train.detach(),dim=1), train_target, num_classes=num_classes)).cpu().numpy()\n",
    "            print('Train - Loss: {:.4f}, Macro_F1: {:.4f}'.format(loss.detach().cpu().numpy(), train_f1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            model.eval()\n",
    "            # Valid\n",
    "            with torch.no_grad():\n",
    "                val_loss, y_valid,_ = model.forward(A, node_features, valid_node, valid_target)\n",
    "                val_f1 = torch.mean(f1_score(torch.argmax(y_valid,dim=1), valid_target, num_classes=num_classes)).cpu().numpy()\n",
    "                print('Valid - Loss: {:.4f}, Macro_F1: {:.4f}'.format(val_loss.detach().cpu().numpy(), val_f1))\n",
    "                test_loss, y_test,W = model.forward(A, node_features, test_node, test_target)\n",
    "                test_f1 = torch.mean(f1_score(torch.argmax(y_test,dim=1), test_target, num_classes=num_classes)).cpu().numpy()\n",
    "                print('Test  - Loss: {:.4f}, Macro_F1: {:.4f}\\n'.format(test_loss.detach().cpu().numpy(), test_f1))\n",
    "            if val_f1 > best_val_f1:\n",
    "                best_val_loss = val_loss.detach().cpu().numpy()\n",
    "                best_test_loss = test_loss.detach().cpu().numpy()\n",
    "                best_train_loss = loss.detach().cpu().numpy()\n",
    "                best_train_f1 = train_f1\n",
    "                best_val_f1 = val_f1\n",
    "                best_test_f1 = test_f1 \n",
    "        print('---------------Best Results--------------------')\n",
    "        print('Train - Loss: {:.4f}, Macro_F1: {:.4f}'.format(best_train_loss, best_train_f1))\n",
    "        print('Valid - Loss: {:.4f}, Macro_F1: {:.4f}'.format(best_val_loss, best_val_f1))\n",
    "        print('Test  - Loss: {:.4f}, Macro_F1: {:.4f}'.format(best_test_loss, best_test_f1))\n",
    "        final_f1 += best_test_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train\n",
    "- restart the notebook after each experiment on a certain dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reproduce on dataset ACM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_40340/4143764818.py:14: DeprecationWarning: Please use `csr_matrix` from the `scipy.sparse` namespace, the `scipy.sparse.csr` namespace is deprecated.\n",
      "  edges = pickle.load(f)\n",
      "/tmp/ipykernel_40340/4143764818.py:14: DeprecationWarning: Please use `csc_matrix` from the `scipy.sparse` namespace, the `scipy.sparse.csc` namespace is deprecated.\n",
      "  edges = pickle.load(f)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node_features.shape torch.Size([8994, 1902])\n",
      "ready to train\n",
      "Epoch:   1\n",
      "Train - Loss: 1.0982, Macro_F1: 0.1667\n",
      "Valid - Loss: 1.0629, Macro_F1: 0.3044\n",
      "Test  - Loss: 1.0679, Macro_F1: 0.3102\n",
      "\n",
      "Epoch:   2\n",
      "Train - Loss: 1.0535, Macro_F1: 0.3365\n",
      "Valid - Loss: 1.0795, Macro_F1: 0.3638\n",
      "Test  - Loss: 1.0709, Macro_F1: 0.3701\n",
      "\n",
      "Epoch:   3\n",
      "Train - Loss: 1.0659, Macro_F1: 0.4221\n",
      "Valid - Loss: 0.9898, Macro_F1: 0.2195\n",
      "Test  - Loss: 0.9834, Macro_F1: 0.2397\n",
      "\n",
      "Epoch:   4\n",
      "Train - Loss: 0.9708, Macro_F1: 0.2629\n",
      "Valid - Loss: 0.9163, Macro_F1: 0.6245\n",
      "Test  - Loss: 0.9183, Macro_F1: 0.6350\n",
      "\n",
      "Epoch:   5\n",
      "Train - Loss: 0.8883, Macro_F1: 0.6835\n",
      "Valid - Loss: 0.8082, Macro_F1: 0.8952\n",
      "Test  - Loss: 0.8170, Macro_F1: 0.8913\n",
      "\n",
      "Epoch:   6\n",
      "Train - Loss: 0.7707, Macro_F1: 0.9345\n",
      "Valid - Loss: 0.6630, Macro_F1: 0.9301\n",
      "Test  - Loss: 0.6740, Macro_F1: 0.9201\n",
      "\n",
      "Epoch:   7\n",
      "Train - Loss: 0.6146, Macro_F1: 0.9548\n",
      "Valid - Loss: 0.5302, Macro_F1: 0.8924\n",
      "Test  - Loss: 0.5424, Macro_F1: 0.8855\n",
      "\n",
      "Epoch:   8\n",
      "Train - Loss: 0.4725, Macro_F1: 0.9419\n",
      "Valid - Loss: 0.3930, Macro_F1: 0.9268\n",
      "Test  - Loss: 0.4114, Macro_F1: 0.9216\n",
      "\n",
      "Epoch:   9\n",
      "Train - Loss: 0.3277, Macro_F1: 0.9616\n",
      "Valid - Loss: 0.3110, Macro_F1: 0.9300\n",
      "Test  - Loss: 0.3365, Macro_F1: 0.9143\n",
      "\n",
      "Epoch:   10\n",
      "Train - Loss: 0.2371, Macro_F1: 0.9532\n",
      "Valid - Loss: 0.2430, Macro_F1: 0.9229\n",
      "Test  - Loss: 0.2737, Macro_F1: 0.9156\n",
      "\n",
      "Epoch:   11\n",
      "Train - Loss: 0.1768, Macro_F1: 0.9597\n",
      "Valid - Loss: 0.2049, Macro_F1: 0.9303\n",
      "Test  - Loss: 0.2353, Macro_F1: 0.9207\n",
      "\n",
      "Epoch:   12\n",
      "Train - Loss: 0.1241, Macro_F1: 0.9633\n",
      "Valid - Loss: 0.2122, Macro_F1: 0.9243\n",
      "Test  - Loss: 0.2437, Macro_F1: 0.9118\n",
      "\n",
      "Epoch:   13\n",
      "Train - Loss: 0.1048, Macro_F1: 0.9651\n",
      "Valid - Loss: 0.1907, Macro_F1: 0.9134\n",
      "Test  - Loss: 0.2247, Macro_F1: 0.9200\n",
      "\n",
      "Epoch:   14\n",
      "Train - Loss: 0.0869, Macro_F1: 0.9716\n",
      "Valid - Loss: 0.1786, Macro_F1: 0.9303\n",
      "Test  - Loss: 0.2162, Macro_F1: 0.9221\n",
      "\n",
      "Epoch:   15\n",
      "Train - Loss: 0.0614, Macro_F1: 0.9750\n",
      "Valid - Loss: 0.1957, Macro_F1: 0.9269\n",
      "Test  - Loss: 0.2428, Macro_F1: 0.9211\n",
      "\n",
      "Epoch:   16\n",
      "Train - Loss: 0.0593, Macro_F1: 0.9817\n",
      "Valid - Loss: 0.1850, Macro_F1: 0.9198\n",
      "Test  - Loss: 0.2272, Macro_F1: 0.9244\n",
      "\n",
      "Epoch:   17\n",
      "Train - Loss: 0.0483, Macro_F1: 0.9816\n",
      "Valid - Loss: 0.1789, Macro_F1: 0.9199\n",
      "Test  - Loss: 0.2229, Macro_F1: 0.9261\n",
      "\n",
      "Epoch:   18\n",
      "Train - Loss: 0.0285, Macro_F1: 0.9900\n",
      "Valid - Loss: 0.2025, Macro_F1: 0.9270\n",
      "Test  - Loss: 0.2566, Macro_F1: 0.9226\n",
      "\n",
      "Epoch:   19\n",
      "Train - Loss: 0.0349, Macro_F1: 0.9867\n",
      "Valid - Loss: 0.1958, Macro_F1: 0.9170\n",
      "Test  - Loss: 0.2384, Macro_F1: 0.9277\n",
      "\n",
      "Epoch:   20\n",
      "Train - Loss: 0.0163, Macro_F1: 0.9967\n",
      "Valid - Loss: 0.2204, Macro_F1: 0.9203\n",
      "Test  - Loss: 0.2601, Macro_F1: 0.9229\n",
      "\n",
      "Epoch:   21\n",
      "Train - Loss: 0.0200, Macro_F1: 0.9917\n",
      "Valid - Loss: 0.2052, Macro_F1: 0.9271\n",
      "Test  - Loss: 0.2523, Macro_F1: 0.9274\n",
      "\n",
      "Epoch:   22\n",
      "Train - Loss: 0.0095, Macro_F1: 1.0000\n",
      "Valid - Loss: 0.2206, Macro_F1: 0.9338\n",
      "Test  - Loss: 0.2735, Macro_F1: 0.9212\n",
      "\n",
      "Epoch:   23\n",
      "Train - Loss: 0.0146, Macro_F1: 0.9967\n",
      "Valid - Loss: 0.2202, Macro_F1: 0.9204\n",
      "Test  - Loss: 0.2645, Macro_F1: 0.9222\n",
      "\n",
      "Epoch:   24\n",
      "Train - Loss: 0.0056, Macro_F1: 1.0000\n",
      "Valid - Loss: 0.2513, Macro_F1: 0.9202\n",
      "Test  - Loss: 0.2913, Macro_F1: 0.9201\n",
      "\n",
      "Epoch:   25\n",
      "Train - Loss: 0.0101, Macro_F1: 0.9983\n",
      "Valid - Loss: 0.2388, Macro_F1: 0.9170\n",
      "Test  - Loss: 0.2819, Macro_F1: 0.9226\n",
      "\n",
      "Epoch:   26\n",
      "Train - Loss: 0.0050, Macro_F1: 1.0000\n",
      "Valid - Loss: 0.2266, Macro_F1: 0.9272\n",
      "Test  - Loss: 0.2777, Macro_F1: 0.9261\n",
      "\n",
      "Epoch:   27\n",
      "Train - Loss: 0.0035, Macro_F1: 1.0000\n",
      "Valid - Loss: 0.2340, Macro_F1: 0.9272\n",
      "Test  - Loss: 0.2909, Macro_F1: 0.9222\n",
      "\n",
      "Epoch:   28\n",
      "Train - Loss: 0.0056, Macro_F1: 1.0000\n",
      "Valid - Loss: 0.2314, Macro_F1: 0.9239\n",
      "Test  - Loss: 0.2861, Macro_F1: 0.9271\n",
      "\n",
      "Epoch:   29\n",
      "Train - Loss: 0.0028, Macro_F1: 1.0000\n",
      "Valid - Loss: 0.2377, Macro_F1: 0.9237\n",
      "Test  - Loss: 0.2879, Macro_F1: 0.9232\n",
      "\n",
      "Epoch:   30\n",
      "Train - Loss: 0.0017, Macro_F1: 1.0000\n",
      "Valid - Loss: 0.2542, Macro_F1: 0.9202\n",
      "Test  - Loss: 0.3017, Macro_F1: 0.9239\n",
      "\n",
      "Epoch:   31\n",
      "Train - Loss: 0.0024, Macro_F1: 1.0000\n",
      "Valid - Loss: 0.2609, Macro_F1: 0.9235\n",
      "Test  - Loss: 0.3084, Macro_F1: 0.9225\n",
      "\n",
      "Epoch:   32\n",
      "Train - Loss: 0.0026, Macro_F1: 1.0000\n",
      "Valid - Loss: 0.2511, Macro_F1: 0.9203\n",
      "Test  - Loss: 0.3011, Macro_F1: 0.9254\n",
      "\n",
      "Epoch:   33\n",
      "Train - Loss: 0.0015, Macro_F1: 1.0000\n",
      "Valid - Loss: 0.2410, Macro_F1: 0.9237\n",
      "Test  - Loss: 0.2946, Macro_F1: 0.9268\n",
      "\n",
      "Epoch:   34\n",
      "Train - Loss: 0.0009, Macro_F1: 1.0000\n",
      "Valid - Loss: 0.2390, Macro_F1: 0.9305\n",
      "Test  - Loss: 0.2963, Macro_F1: 0.9252\n",
      "\n",
      "Epoch:   35\n",
      "Train - Loss: 0.0010, Macro_F1: 1.0000\n",
      "Valid - Loss: 0.2424, Macro_F1: 0.9272\n",
      "Test  - Loss: 0.3022, Macro_F1: 0.9239\n",
      "\n",
      "Epoch:   36\n",
      "Train - Loss: 0.0013, Macro_F1: 1.0000\n",
      "Valid - Loss: 0.2436, Macro_F1: 0.9272\n",
      "Test  - Loss: 0.3038, Macro_F1: 0.9239\n",
      "\n",
      "Epoch:   37\n",
      "Train - Loss: 0.0012, Macro_F1: 1.0000\n",
      "Valid - Loss: 0.2414, Macro_F1: 0.9272\n",
      "Test  - Loss: 0.3002, Macro_F1: 0.9257\n",
      "\n",
      "Epoch:   38\n",
      "Train - Loss: 0.0008, Macro_F1: 1.0000\n",
      "Valid - Loss: 0.2402, Macro_F1: 0.9304\n",
      "Test  - Loss: 0.2969, Macro_F1: 0.9256\n",
      "\n",
      "Epoch:   39\n",
      "Train - Loss: 0.0006, Macro_F1: 1.0000\n",
      "Valid - Loss: 0.2426, Macro_F1: 0.9204\n",
      "Test  - Loss: 0.2970, Macro_F1: 0.9264\n",
      "\n",
      "Epoch:   40\n",
      "Train - Loss: 0.0005, Macro_F1: 1.0000\n",
      "Valid - Loss: 0.2469, Macro_F1: 0.9171\n",
      "Test  - Loss: 0.2996, Macro_F1: 0.9259\n",
      "\n",
      "---------------Best Results--------------------\n",
      "Train - Loss: 0.0095, Macro_F1: 1.0000\n",
      "Valid - Loss: 0.2206, Macro_F1: 0.9338\n",
      "Test  - Loss: 0.2735, Macro_F1: 0.9212\n"
     ]
    }
   ],
   "source": [
    "args = Argument(dataset=\"ACM\",num_layers=2,epoch=40,adaptive_lr=True)\n",
    "set_global_random_seed(args.seed) \n",
    "train(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reproduce on dataset IMDB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7516/4143764818.py:14: DeprecationWarning: Please use `csr_matrix` from the `scipy.sparse` namespace, the `scipy.sparse.csr` namespace is deprecated.\n",
      "  edges = pickle.load(f)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node_features.shape torch.Size([12772, 1256])\n",
      "ready to train\n",
      "Epoch:   1\n",
      "Train - Loss: 1.1035, Macro_F1: 0.1667\n",
      "Valid - Loss: 1.0995, Macro_F1: 0.1667\n",
      "Test  - Loss: 1.0643, Macro_F1: 0.2348\n",
      "\n",
      "Epoch:   2\n",
      "Train - Loss: 1.0951, Macro_F1: 0.1667\n",
      "Valid - Loss: 1.0950, Macro_F1: 0.1667\n",
      "Test  - Loss: 1.0705, Macro_F1: 0.2348\n",
      "\n",
      "Epoch:   3\n",
      "Train - Loss: 1.0856, Macro_F1: 0.1667\n",
      "Valid - Loss: 1.0885, Macro_F1: 0.1940\n",
      "Test  - Loss: 1.0735, Macro_F1: 0.2513\n",
      "\n",
      "Epoch:   4\n",
      "Train - Loss: 1.0711, Macro_F1: 0.2950\n",
      "Valid - Loss: 1.0782, Macro_F1: 0.4525\n",
      "Test  - Loss: 1.0715, Macro_F1: 0.4601\n",
      "\n",
      "Epoch:   5\n",
      "Train - Loss: 1.0490, Macro_F1: 0.7879\n",
      "Valid - Loss: 1.0625, Macro_F1: 0.6485\n",
      "Test  - Loss: 1.0625, Macro_F1: 0.5754\n",
      "\n",
      "Epoch:   6\n",
      "Train - Loss: 1.0164, Macro_F1: 0.9303\n",
      "Valid - Loss: 1.0387, Macro_F1: 0.6744\n",
      "Test  - Loss: 1.0450, Macro_F1: 0.5925\n",
      "\n",
      "Epoch:   7\n",
      "Train - Loss: 0.9697, Macro_F1: 0.9434\n",
      "Valid - Loss: 1.0048, Macro_F1: 0.6833\n",
      "Test  - Loss: 1.0196, Macro_F1: 0.5962\n",
      "\n",
      "Epoch:   8\n",
      "Train - Loss: 0.9051, Macro_F1: 0.9400\n",
      "Valid - Loss: 0.9604, Macro_F1: 0.7008\n",
      "Test  - Loss: 0.9908, Macro_F1: 0.5875\n",
      "\n",
      "Epoch:   9\n",
      "Train - Loss: 0.8205, Macro_F1: 0.9501\n",
      "Valid - Loss: 0.9081, Macro_F1: 0.7000\n",
      "Test  - Loss: 0.9630, Macro_F1: 0.5743\n",
      "\n",
      "Epoch:   10\n",
      "Train - Loss: 0.7187, Macro_F1: 0.9467\n",
      "Valid - Loss: 0.8549, Macro_F1: 0.6734\n",
      "Test  - Loss: 0.9349, Macro_F1: 0.5649\n",
      "\n",
      "Epoch:   11\n",
      "Train - Loss: 0.6063, Macro_F1: 0.9567\n",
      "Valid - Loss: 0.8081, Macro_F1: 0.6672\n",
      "Test  - Loss: 0.9048, Macro_F1: 0.5690\n",
      "\n",
      "Epoch:   12\n",
      "Train - Loss: 0.4923, Macro_F1: 0.9533\n",
      "Valid - Loss: 0.7730, Macro_F1: 0.6697\n",
      "Test  - Loss: 0.8826, Macro_F1: 0.5781\n",
      "\n",
      "Epoch:   13\n",
      "Train - Loss: 0.3851, Macro_F1: 0.9567\n",
      "Valid - Loss: 0.7532, Macro_F1: 0.6750\n",
      "Test  - Loss: 0.8813, Macro_F1: 0.5788\n",
      "\n",
      "Epoch:   14\n",
      "Train - Loss: 0.2906, Macro_F1: 0.9700\n",
      "Valid - Loss: 0.7504, Macro_F1: 0.6574\n",
      "Test  - Loss: 0.9065, Macro_F1: 0.5785\n",
      "\n",
      "Epoch:   15\n",
      "Train - Loss: 0.2117, Macro_F1: 0.9833\n",
      "Valid - Loss: 0.7654, Macro_F1: 0.6512\n",
      "Test  - Loss: 0.9585, Macro_F1: 0.5750\n",
      "\n",
      "Epoch:   16\n",
      "Train - Loss: 0.1492, Macro_F1: 0.9900\n",
      "Valid - Loss: 0.7976, Macro_F1: 0.6380\n",
      "Test  - Loss: 1.0358, Macro_F1: 0.5705\n",
      "\n",
      "Epoch:   17\n",
      "Train - Loss: 0.1028, Macro_F1: 0.9967\n",
      "Valid - Loss: 0.8449, Macro_F1: 0.6336\n",
      "Test  - Loss: 1.1370, Macro_F1: 0.5645\n",
      "\n",
      "Epoch:   18\n",
      "Train - Loss: 0.0704, Macro_F1: 0.9967\n",
      "Valid - Loss: 0.9020, Macro_F1: 0.6312\n",
      "Test  - Loss: 1.2540, Macro_F1: 0.5615\n",
      "\n",
      "Epoch:   19\n",
      "Train - Loss: 0.0483, Macro_F1: 0.9967\n",
      "Valid - Loss: 0.9640, Macro_F1: 0.6421\n",
      "Test  - Loss: 1.3777, Macro_F1: 0.5594\n",
      "\n",
      "Epoch:   20\n",
      "Train - Loss: 0.0336, Macro_F1: 0.9967\n",
      "Valid - Loss: 1.0273, Macro_F1: 0.6460\n",
      "Test  - Loss: 1.4988, Macro_F1: 0.5594\n",
      "\n",
      "Epoch:   21\n",
      "Train - Loss: 0.0240, Macro_F1: 0.9967\n",
      "Valid - Loss: 1.0887, Macro_F1: 0.6496\n",
      "Test  - Loss: 1.6096, Macro_F1: 0.5556\n",
      "\n",
      "Epoch:   22\n",
      "Train - Loss: 0.0177, Macro_F1: 0.9967\n",
      "Valid - Loss: 1.1448, Macro_F1: 0.6560\n",
      "Test  - Loss: 1.7041, Macro_F1: 0.5532\n",
      "\n",
      "Epoch:   23\n",
      "Train - Loss: 0.0134, Macro_F1: 0.9967\n",
      "Valid - Loss: 1.1942, Macro_F1: 0.6460\n",
      "Test  - Loss: 1.7815, Macro_F1: 0.5547\n",
      "\n",
      "Epoch:   24\n",
      "Train - Loss: 0.0104, Macro_F1: 0.9967\n",
      "Valid - Loss: 1.2360, Macro_F1: 0.6491\n",
      "Test  - Loss: 1.8428, Macro_F1: 0.5568\n",
      "\n",
      "Epoch:   25\n",
      "Train - Loss: 0.0083, Macro_F1: 0.9967\n",
      "Valid - Loss: 1.2709, Macro_F1: 0.6491\n",
      "Test  - Loss: 1.8901, Macro_F1: 0.5570\n",
      "\n",
      "Epoch:   26\n",
      "Train - Loss: 0.0066, Macro_F1: 0.9967\n",
      "Valid - Loss: 1.2990, Macro_F1: 0.6526\n",
      "Test  - Loss: 1.9250, Macro_F1: 0.5582\n",
      "\n",
      "Epoch:   27\n",
      "Train - Loss: 0.0053, Macro_F1: 0.9967\n",
      "Valid - Loss: 1.3205, Macro_F1: 0.6528\n",
      "Test  - Loss: 1.9492, Macro_F1: 0.5554\n",
      "\n",
      "Epoch:   28\n",
      "Train - Loss: 0.0043, Macro_F1: 1.0000\n",
      "Valid - Loss: 1.3360, Macro_F1: 0.6570\n",
      "Test  - Loss: 1.9646, Macro_F1: 0.5538\n",
      "\n",
      "Epoch:   29\n",
      "Train - Loss: 0.0036, Macro_F1: 1.0000\n",
      "Valid - Loss: 1.3457, Macro_F1: 0.6501\n",
      "Test  - Loss: 1.9730, Macro_F1: 0.5497\n",
      "\n",
      "Epoch:   30\n",
      "Train - Loss: 0.0029, Macro_F1: 1.0000\n",
      "Valid - Loss: 1.3506, Macro_F1: 0.6571\n",
      "Test  - Loss: 1.9758, Macro_F1: 0.5507\n",
      "\n",
      "Epoch:   31\n",
      "Train - Loss: 0.0025, Macro_F1: 1.0000\n",
      "Valid - Loss: 1.3507, Macro_F1: 0.6464\n",
      "Test  - Loss: 1.9746, Macro_F1: 0.5460\n",
      "\n",
      "Epoch:   32\n",
      "Train - Loss: 0.0021, Macro_F1: 1.0000\n",
      "Valid - Loss: 1.3471, Macro_F1: 0.6458\n",
      "Test  - Loss: 1.9709, Macro_F1: 0.5487\n",
      "\n",
      "Epoch:   33\n",
      "Train - Loss: 0.0019, Macro_F1: 1.0000\n",
      "Valid - Loss: 1.3403, Macro_F1: 0.6458\n",
      "Test  - Loss: 1.9652, Macro_F1: 0.5492\n",
      "\n",
      "Epoch:   34\n",
      "Train - Loss: 0.0018, Macro_F1: 1.0000\n",
      "Valid - Loss: 1.3310, Macro_F1: 0.6519\n",
      "Test  - Loss: 1.9575, Macro_F1: 0.5481\n",
      "\n",
      "Epoch:   35\n",
      "Train - Loss: 0.0017, Macro_F1: 1.0000\n",
      "Valid - Loss: 1.3192, Macro_F1: 0.6582\n",
      "Test  - Loss: 1.9470, Macro_F1: 0.5459\n",
      "\n",
      "Epoch:   36\n",
      "Train - Loss: 0.0017, Macro_F1: 1.0000\n",
      "Valid - Loss: 1.3046, Macro_F1: 0.6550\n",
      "Test  - Loss: 1.9308, Macro_F1: 0.5494\n",
      "\n",
      "Epoch:   37\n",
      "Train - Loss: 0.0018, Macro_F1: 1.0000\n",
      "Valid - Loss: 1.2863, Macro_F1: 0.6588\n",
      "Test  - Loss: 1.9054, Macro_F1: 0.5504\n",
      "\n",
      "Epoch:   38\n",
      "Train - Loss: 0.0020, Macro_F1: 1.0000\n",
      "Valid - Loss: 1.2636, Macro_F1: 0.6525\n",
      "Test  - Loss: 1.8689, Macro_F1: 0.5476\n",
      "\n",
      "Epoch:   39\n",
      "Train - Loss: 0.0021, Macro_F1: 1.0000\n",
      "Valid - Loss: 1.2379, Macro_F1: 0.6525\n",
      "Test  - Loss: 1.8228, Macro_F1: 0.5505\n",
      "\n",
      "Epoch:   40\n",
      "Train - Loss: 0.0023, Macro_F1: 1.0000\n",
      "Valid - Loss: 1.2113, Macro_F1: 0.6563\n",
      "Test  - Loss: 1.7731, Macro_F1: 0.5500\n",
      "\n",
      "---------------Best Results--------------------\n",
      "Train - Loss: 0.9051, Macro_F1: 0.9400\n",
      "Valid - Loss: 0.9604, Macro_F1: 0.7008\n",
      "Test  - Loss: 0.9908, Macro_F1: 0.5875\n"
     ]
    }
   ],
   "source": [
    "args = Argument(dataset=\"IMDB\",num_layers=3,epoch=40,adaptive_lr=True)\n",
    "set_global_random_seed(args.seed) \n",
    "train(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reproduce on dataset DBLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11779/4143764818.py:14: DeprecationWarning: Please use `csr_matrix` from the `scipy.sparse` namespace, the `scipy.sparse.csr` namespace is deprecated.\n",
      "  edges = pickle.load(f)\n",
      "/tmp/ipykernel_11779/4143764818.py:14: DeprecationWarning: Please use `csc_matrix` from the `scipy.sparse` namespace, the `scipy.sparse.csc` namespace is deprecated.\n",
      "  edges = pickle.load(f)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node_features.shape torch.Size([18405, 334])\n",
      "ready to train\n",
      "Epoch:   1\n",
      "Train - Loss: 1.3866, Macro_F1: 0.1087\n",
      "Valid - Loss: 1.3591, Macro_F1: 0.2508\n",
      "Test  - Loss: 1.3665, Macro_F1: 0.1987\n",
      "\n",
      "Epoch:   2\n",
      "Train - Loss: 1.3591, Macro_F1: 0.2403\n",
      "Valid - Loss: 1.3017, Macro_F1: 0.5891\n",
      "Test  - Loss: 1.3104, Macro_F1: 0.5370\n",
      "\n",
      "Epoch:   3\n",
      "Train - Loss: 1.3002, Macro_F1: 0.5919\n",
      "Valid - Loss: 1.1967, Macro_F1: 0.7573\n",
      "Test  - Loss: 1.2067, Macro_F1: 0.7228\n",
      "\n",
      "Epoch:   4\n",
      "Train - Loss: 1.1942, Macro_F1: 0.7683\n",
      "Valid - Loss: 1.0251, Macro_F1: 0.9208\n",
      "Test  - Loss: 1.0305, Macro_F1: 0.8845\n",
      "\n",
      "Epoch:   5\n",
      "Train - Loss: 1.0254, Macro_F1: 0.8938\n",
      "Valid - Loss: 0.8264, Macro_F1: 0.9400\n",
      "Test  - Loss: 0.8319, Macro_F1: 0.9259\n",
      "\n",
      "Epoch:   6\n",
      "Train - Loss: 0.8320, Macro_F1: 0.9206\n",
      "Valid - Loss: 0.7740, Macro_F1: 0.7475\n",
      "Test  - Loss: 0.7951, Macro_F1: 0.6875\n",
      "\n",
      "Epoch:   7\n",
      "Train - Loss: 0.7865, Macro_F1: 0.7166\n",
      "Valid - Loss: 0.7782, Macro_F1: 0.7261\n",
      "Test  - Loss: 0.8349, Macro_F1: 0.6852\n",
      "\n",
      "Epoch:   8\n",
      "Train - Loss: 0.7628, Macro_F1: 0.7345\n",
      "Valid - Loss: 0.8200, Macro_F1: 0.4834\n",
      "Test  - Loss: 0.8498, Macro_F1: 0.4510\n",
      "\n",
      "Epoch:   9\n",
      "Train - Loss: 0.8774, Macro_F1: 0.4769\n",
      "Valid - Loss: 0.4181, Macro_F1: 0.9125\n",
      "Test  - Loss: 0.4323, Macro_F1: 0.9013\n",
      "\n",
      "Epoch:   10\n",
      "Train - Loss: 0.4664, Macro_F1: 0.8949\n",
      "Valid - Loss: 0.5494, Macro_F1: 0.8577\n",
      "Test  - Loss: 0.5747, Macro_F1: 0.8416\n",
      "\n",
      "Epoch:   11\n",
      "Train - Loss: 0.5421, Macro_F1: 0.8618\n",
      "Valid - Loss: 0.6451, Macro_F1: 0.8122\n",
      "Test  - Loss: 0.6714, Macro_F1: 0.7913\n",
      "\n",
      "Epoch:   12\n",
      "Train - Loss: 0.6181, Macro_F1: 0.8110\n",
      "Valid - Loss: 0.4244, Macro_F1: 0.8906\n",
      "Test  - Loss: 0.4392, Macro_F1: 0.8744\n",
      "\n",
      "Epoch:   13\n",
      "Train - Loss: 0.4277, Macro_F1: 0.8780\n",
      "Valid - Loss: 0.2758, Macro_F1: 0.9298\n",
      "Test  - Loss: 0.2881, Macro_F1: 0.9172\n",
      "\n",
      "Epoch:   14\n",
      "Train - Loss: 0.3177, Macro_F1: 0.9177\n",
      "Valid - Loss: 0.3356, Macro_F1: 0.9402\n",
      "Test  - Loss: 0.3494, Macro_F1: 0.9228\n",
      "\n",
      "Epoch:   15\n",
      "Train - Loss: 0.3858, Macro_F1: 0.9030\n",
      "Valid - Loss: 0.3451, Macro_F1: 0.9259\n",
      "Test  - Loss: 0.3596, Macro_F1: 0.9156\n",
      "\n",
      "Epoch:   16\n",
      "Train - Loss: 0.3886, Macro_F1: 0.8989\n",
      "Valid - Loss: 0.2565, Macro_F1: 0.9303\n",
      "Test  - Loss: 0.2611, Macro_F1: 0.9361\n",
      "\n",
      "Epoch:   17\n",
      "Train - Loss: 0.2879, Macro_F1: 0.9300\n",
      "Valid - Loss: 0.2478, Macro_F1: 0.9371\n",
      "Test  - Loss: 0.2497, Macro_F1: 0.9266\n",
      "\n",
      "Epoch:   18\n",
      "Train - Loss: 0.2692, Macro_F1: 0.9137\n",
      "Valid - Loss: 0.2676, Macro_F1: 0.9319\n",
      "Test  - Loss: 0.2760, Macro_F1: 0.9067\n",
      "\n",
      "Epoch:   19\n",
      "Train - Loss: 0.2845, Macro_F1: 0.8995\n",
      "Valid - Loss: 0.2724, Macro_F1: 0.9221\n",
      "Test  - Loss: 0.2891, Macro_F1: 0.8958\n",
      "\n",
      "Epoch:   20\n",
      "Train - Loss: 0.2902, Macro_F1: 0.9068\n",
      "Valid - Loss: 0.2570, Macro_F1: 0.9245\n",
      "Test  - Loss: 0.2784, Macro_F1: 0.8977\n",
      "\n",
      "Epoch:   21\n",
      "Train - Loss: 0.2822, Macro_F1: 0.9113\n",
      "Valid - Loss: 0.2179, Macro_F1: 0.9323\n",
      "Test  - Loss: 0.2373, Macro_F1: 0.9118\n",
      "\n",
      "Epoch:   22\n",
      "Train - Loss: 0.2543, Macro_F1: 0.9165\n",
      "Valid - Loss: 0.1831, Macro_F1: 0.9299\n",
      "Test  - Loss: 0.1928, Macro_F1: 0.9325\n",
      "\n",
      "Epoch:   23\n",
      "Train - Loss: 0.2273, Macro_F1: 0.9351\n",
      "Valid - Loss: 0.1904, Macro_F1: 0.9449\n",
      "Test  - Loss: 0.1854, Macro_F1: 0.9384\n",
      "\n",
      "Epoch:   24\n",
      "Train - Loss: 0.2330, Macro_F1: 0.9311\n",
      "Valid - Loss: 0.2099, Macro_F1: 0.9350\n",
      "Test  - Loss: 0.1986, Macro_F1: 0.9401\n",
      "\n",
      "Epoch:   25\n",
      "Train - Loss: 0.2472, Macro_F1: 0.9261\n",
      "Valid - Loss: 0.1987, Macro_F1: 0.9375\n",
      "Test  - Loss: 0.1889, Macro_F1: 0.9410\n",
      "\n",
      "Epoch:   26\n",
      "Train - Loss: 0.2340, Macro_F1: 0.9299\n",
      "Valid - Loss: 0.1797, Macro_F1: 0.9450\n",
      "Test  - Loss: 0.1764, Macro_F1: 0.9402\n",
      "\n",
      "Epoch:   27\n",
      "Train - Loss: 0.2168, Macro_F1: 0.9325\n",
      "Valid - Loss: 0.1731, Macro_F1: 0.9372\n",
      "Test  - Loss: 0.1788, Macro_F1: 0.9354\n",
      "\n",
      "Epoch:   28\n",
      "Train - Loss: 0.2136, Macro_F1: 0.9326\n",
      "Valid - Loss: 0.1768, Macro_F1: 0.9371\n",
      "Test  - Loss: 0.1905, Macro_F1: 0.9273\n",
      "\n",
      "Epoch:   29\n",
      "Train - Loss: 0.2198, Macro_F1: 0.9252\n",
      "Valid - Loss: 0.1808, Macro_F1: 0.9371\n",
      "Test  - Loss: 0.1970, Macro_F1: 0.9239\n",
      "\n",
      "Epoch:   30\n",
      "Train - Loss: 0.2221, Macro_F1: 0.9240\n",
      "Valid - Loss: 0.1805, Macro_F1: 0.9396\n",
      "Test  - Loss: 0.1937, Macro_F1: 0.9248\n",
      "\n",
      "Epoch:   31\n",
      "Train - Loss: 0.2177, Macro_F1: 0.9265\n",
      "Valid - Loss: 0.1776, Macro_F1: 0.9322\n",
      "Test  - Loss: 0.1845, Macro_F1: 0.9318\n",
      "\n",
      "Epoch:   32\n",
      "Train - Loss: 0.2116, Macro_F1: 0.9239\n",
      "Valid - Loss: 0.1747, Macro_F1: 0.9348\n",
      "Test  - Loss: 0.1742, Macro_F1: 0.9380\n",
      "\n",
      "Epoch:   33\n",
      "Train - Loss: 0.2079, Macro_F1: 0.9313\n",
      "Valid - Loss: 0.1738, Macro_F1: 0.9348\n",
      "Test  - Loss: 0.1677, Macro_F1: 0.9402\n",
      "\n",
      "Epoch:   34\n",
      "Train - Loss: 0.2080, Macro_F1: 0.9362\n",
      "Valid - Loss: 0.1731, Macro_F1: 0.9400\n",
      "Test  - Loss: 0.1659, Macro_F1: 0.9417\n",
      "\n",
      "Epoch:   35\n",
      "Train - Loss: 0.2094, Macro_F1: 0.9312\n",
      "Valid - Loss: 0.1708, Macro_F1: 0.9450\n",
      "Test  - Loss: 0.1666, Macro_F1: 0.9432\n",
      "\n",
      "Epoch:   36\n",
      "Train - Loss: 0.2091, Macro_F1: 0.9299\n",
      "Valid - Loss: 0.1671, Macro_F1: 0.9450\n",
      "Test  - Loss: 0.1674, Macro_F1: 0.9434\n",
      "\n",
      "Epoch:   37\n",
      "Train - Loss: 0.2061, Macro_F1: 0.9325\n",
      "Valid - Loss: 0.1638, Macro_F1: 0.9374\n",
      "Test  - Loss: 0.1682, Macro_F1: 0.9411\n",
      "\n",
      "Epoch:   38\n",
      "Train - Loss: 0.2021, Macro_F1: 0.9326\n",
      "Valid - Loss: 0.1647, Macro_F1: 0.9424\n",
      "Test  - Loss: 0.1713, Macro_F1: 0.9379\n",
      "\n",
      "Epoch:   39\n",
      "Train - Loss: 0.2004, Macro_F1: 0.9325\n",
      "Valid - Loss: 0.1694, Macro_F1: 0.9448\n",
      "Test  - Loss: 0.1764, Macro_F1: 0.9349\n",
      "\n",
      "Epoch:   40\n",
      "Train - Loss: 0.2016, Macro_F1: 0.9288\n",
      "Valid - Loss: 0.1721, Macro_F1: 0.9422\n",
      "Test  - Loss: 0.1794, Macro_F1: 0.9332\n",
      "\n",
      "---------------Best Results--------------------\n",
      "Train - Loss: 0.2340, Macro_F1: 0.9299\n",
      "Valid - Loss: 0.1797, Macro_F1: 0.9450\n",
      "Test  - Loss: 0.1764, Macro_F1: 0.9402\n"
     ]
    }
   ],
   "source": [
    "args = Argument(dataset=\"DBLP\",num_layers=3,epoch=40,adaptive_lr=False)\n",
    "set_global_random_seed(args.seed) \n",
    "train(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Table 1: Evaluation results on the node classification task (F1 score)\n",
    "|            | result in paper    |  reproduce result  |\n",
    "| :-:   | :-:   | :-: |\n",
    "| DBLP        | 94.18      |   94.02    |\n",
    "| ACM        | 92.68      |   92.12    |\n",
    "| IMDB        | 60.92      |   58.75    |"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2f394aca7ca06fed1e6064aef884364492d7cdda3614a461e02e6407fc40ba69"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
